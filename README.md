# MNIST Handwritten Digit Classification ğŸ–Šï¸ğŸ”¢

A deep learning project that classifies handwritten digits (0â€“9) from the **MNIST dataset** using a fully connected neural network built with TensorFlow/Keras.

---

## ğŸ“Œ Project Overview

- Implemented a **feedforward neural network classifier** for MNIST digit recognition
- Preprocessed and normalized 28Ã—28 grayscale images
- Visualized training data and model predictions
- Trained on 60,000 images and evaluated on 10,000 test images
- Achieved strong classification performance on unseen handwritten digits

---

## ğŸš€ Features

- âœ… Loads MNIST dataset via `keras.datasets.mnist`
- âœ… Data preprocessing: normalization and flattening
- âœ… Visualization tools using `matplotlib`, `seaborn`, and `OpenCV`
- âœ… Deep neural network with 2 hidden layers
- âœ… Model evaluation with accuracy metrics and confusion matrix
- âœ… Sample prediction visualization on test images

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ MnistdigitClassification.ipynb   # Main notebook with full workflow
â”œâ”€â”€ README.md                         # Project documentation
â””â”€â”€ requirements.txt                  # Python dependencies
```

---

## âš™ï¸ Requirements

Install all dependencies with:

```bash
pip install numpy matplotlib seaborn opencv-python pillow tensorflow
```

Or use the provided `requirements.txt`:

```bash
pip install -r requirements.txt
```

**Required Libraries:**
- `numpy` - Numerical computing
- `matplotlib` - Data visualization
- `seaborn` - Statistical plotting
- `opencv-python` (cv2) - Image processing
- `pillow` (PIL) - Image handling
- `tensorflow` - Deep learning framework (Keras API)

---

## ğŸ“Š Dataset

**MNIST Handwritten Digits Database**
- ğŸ“¥ 60,000 training images
- ğŸ“¥ 10,000 test images
- ğŸ“ Image size: **28Ã—28 pixels** (grayscale)
- ğŸ·ï¸ Labels: 10 classes (digits 0â€“9)

The dataset is automatically downloaded via `keras.datasets.mnist.load_data()`.

---

## ğŸ—ï¸ Model Architecture

**Type:** Fully Connected Neural Network (Feedforward)

```python
model = keras.Sequential([
    keras.layers.Flatten(input_shape=(28, 28)),  # Input: 28Ã—28 â†’ 784 features
    keras.layers.Dense(50, activation='relu'),   # Hidden layer 1: 50 neurons
    keras.layers.Dense(50, activation='relu'),   # Hidden layer 2: 50 neurons
    keras.layers.Dense(10, activation='sigmoid') # Output layer: 10 classes
])
```

**Model Configuration:**
- **Optimizer:** Adam
- **Loss Function:** Sparse Categorical Crossentropy
- **Metrics:** Accuracy
- **Training:** 10 epochs

**Layer Breakdown:**
1. **Input Layer:** Flattens 28Ã—28 images into 784-dimensional vectors
2. **Hidden Layer 1:** 50 neurons with ReLU activation
3. **Hidden Layer 2:** 50 neurons with ReLU activation
4. **Output Layer:** 10 neurons with sigmoid activation (one per digit class)

---

## ğŸ“ˆ Results

**Training Configuration:**
- Epochs: 10
- Training samples: 60,000
- Test samples: 10,000

**Performance:**
- Training accuracy: ~97-98%
- Test accuracy: ~97%+
- Model generalizes well across all digit classes (0â€“9)

> **Note:** Exact accuracy values can be found in the notebook output cells.

---

## ğŸ“Š Visualizations

The notebook includes:
- ğŸ“¸ Sample training images with labels
- ğŸ“‰ Training loss and accuracy curves over epochs
- ğŸ¯ Confusion matrix showing classification performance per digit
- âœ… Correctly classified vs. âŒ misclassified digit examples
- ğŸ”® Prediction visualizations on test set

---

## â–¶ï¸ How to Run

### 1ï¸âƒ£ Clone the Repository

```bash
git clone <your-repo-url>
cd mnist-digit-classification
```

### 2ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

### 3ï¸âƒ£ Launch Jupyter Notebook

```bash
jupyter notebook MnistdigitClassification.ipynb
```

### 4ï¸âƒ£ Run the Notebook

- Execute all cells sequentially (`Cell > Run All`)
- The model will train automatically and display results
- Visualizations will appear inline

---

## ğŸ” Key Steps in the Notebook

1. **Data Loading:** Import MNIST dataset
2. **Exploration:** Check data shapes and visualize samples
3. **Preprocessing:** Normalize pixel values (0â€“1 range)
4. **Model Building:** Define neural network architecture
5. **Training:** Fit model on training data
6. **Evaluation:** Test on unseen data and calculate accuracy
7. **Visualization:** Plot predictions and confusion matrix

---

## ğŸ“Œ Future Improvements

- ğŸ§  Implement **Convolutional Neural Networks (CNNs)** for improved accuracy (>99%)
- ğŸ”„ Add **data augmentation** (rotation, shifting) for robustness
- ğŸ“Š Experiment with different architectures (deeper networks, dropout layers)
- ğŸ¨ Create an interactive **digit drawing interface** for real-time predictions
- ğŸš€ Deploy model as a web app using Flask/Streamlit
- ğŸ”§ Hyperparameter tuning (learning rate, batch size, optimizer)

---

## ğŸ“ License

This project is licensed under the **MIT License** - feel free to use and modify.

---

## ğŸ‘¨â€ğŸ’» Author

Developed as a deep learning practice project for handwritten digit recognition.

---

## ğŸ™ Acknowledgments

- MNIST dataset by Yann LeCun, Corinna Cortes, and Christopher J.C. Burges
- TensorFlow/Keras documentation and tutorials
- Deep learning community resources

---

**â­ If you found this project helpful, consider giving it a star!**
